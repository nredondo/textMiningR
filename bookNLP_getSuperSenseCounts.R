###### get bookNLP supersense counts from corpus ######
#this script produces a document-term matrix where the terms are "super-senses" generated by bookNLP
#INPUT: directory of bookNLP tables
#OUPUT: single table of supersense counts by book normalized by total tokens

library(dplyr)

#set root working directory
#wd.root<-c("/Users/akpiper/Data/CONLIT_NLP/")
wd.root<-c("/Users/akpiper/Research/WorldLit/WORLDLIT1.0_TXT_EN_bookNLP/")

setwd(wd.root)

#get list of folders (i.e. books)
filenames<-list.files()

#create empty final table
final.df<-NULL

#for every book
for (i in 1:length(filenames)){

  print(i)
  
  #setwd to the i-th book
  wd.file<-paste(wd.root, filenames[i], sep="")
  setwd(wd.file)
  
  #get list of files
  book.files<-list.files()
  
  #check to see if the directory has all necessary files
  if (length(book.files) == 6){
    
    #load supersense file
    super<-book.files[grep(".supersense", book.files)]
    super.df<-read.csv(super, quote="", sep="\t")
    #super.df<-read.csv(filenames[i])
    
    #table supersense types
    super.table<-table(super.df$supersense_category)
    
    #normalize by word count
    super.table<-super.table/max(super.df$end_token)
    #super.table<-super.table/nrow(super.df)
    
    #turn into data frame
    super.table<-as.data.frame(super.table)
    
    #make sure it was populated
    if (nrow(super.table) > 0){
      
    if (i == 1){
      final.df<-super.table
    } else {
    #add to meta table
      final.df<-merge(final.df, super.table, by=c("Var1"), all=TRUE)
    }
    #rename columns
    colnames(final.df)[length(colnames(final.df))]<-filenames[i]
    }
  }
}

#transpose columns to rows and clean up
df<-as.data.frame(t(final.df))
colnames(df)<-df[1,]
df<-df[-1,]
df[is.na(df)]<-0
filename<-row.names(df)
df<-apply(df, 2, as.numeric)
df<-as.data.frame(df)
df$filename<-filename

#setwd("/Users/akpiper/Data/")
write.csv(df, file="WORLDLIT1.0_TXT_EN_bookNLP_Supersense.csv", row.names = F)
